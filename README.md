# â­•âŒ _**Deep Knowledge Tracing**_
<p align='center'>
<img src=https://user-images.githubusercontent.com/63627253/119375251-8f2c8100-bcf5-11eb-89b7-583434f96171.gif width=75%>
</p>

</br>

## **Task Description**

#### Task
í•™ìƒì´ í‘¼ ë¬¸ì œ ë¦¬ìŠ¤íŠ¸ì™€ ì •ë‹µ ì—¬ë¶€ê°€ ë‹´ê¸´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ **í•™ìƒì˜ ì§€ì‹ìƒíƒœë¥¼ ì¶”ì **í•˜ê³ , ë¯¸ë˜ì— í•™ìƒì´ íŠ¹ì • ë¬¸ì œë¥¼ ë§ì¶œì§€ í‹€ë¦´ì§€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
ì´ë¥¼ í†µí•´ í•™ìƒì—ê²Œ **ê°œì¸ ë§ì¶¤í˜• êµìœ¡**ì„ ì œê³µí•©ë‹ˆë‹¤.
#### Metric
**AUROC**, Accuracy

</br>

## Pipeline
![freshtomato_pipeline](https://user-images.githubusercontent.com/46676700/122864044-da6e9980-d35e-11eb-8cc7-75a24b1d3771.png)

## **Command Line Interface**

## **1ï¸âƒ£ Train/Valid Ratio 9:1 (random split)**

#### Train Phase
```python
>>> cd code
>>> python train.py --wandb_project_name [PROJECT_NAME] --wandb_run_name [RUN_NAME] --model [MODEL]
```

#### Inference Phase
```python
>>> cd code
>>> python inference.py --wandb_run_name [RUN_NAME] --model [MODEL]
```

## **2ï¸âƒ£ K-fold**

#### Train Phase
```python
>>> cd code
>>> python train_kfold.py --wandb_project_name [PROJECT_NAME] --wandb_run_name [RUN_NAME] --model [MODEL] --kfold 10
```

#### Inference Phase
```python
>>> cd code
>>> python inference_kfold.py --wandb_run_name [RUN_NAME] --model [MODEL] --kfold 10
```

## **3ï¸âƒ£ Stratified K-fold**

#### Train Phase
```python
>>> cd code
>>> python train_stfkfold.py --wandb_project_name [PROJECT_NAME] --wandb_run_name [RUN_NAME] --model [MODEL] --kfold 10
```

#### Inference Phase
```python
>>> cd code
>>> python inference_kfold.py --wandb_run_name [RUN_NAME] --model [MODEL] --kfold 10
```

</br>

## **Implemented models**
- LSTM (lstm)
- LSTM + Attention (lstmattn)
- Bert (bert)
- GRUATTN (gruattn)
- ATTNGRU (attngru)
- Saint (saint)
- Saint_custom (saintcustom)
- LastQuery (lastquery)
- BaseCNN (cnn)
- DeepCNN (deepcnn)


## Directory structure

```bash
â”œâ”€â”€ README.md                 - ë¦¬ë“œë¯¸ íŒŒì¼
â”‚
â”œâ”€â”€ requirements.md           - í•„ìš”í•œ library
|
â”œâ”€â”€ dkt/                      - DLíŒ€ utils íŒŒì¼
â”‚   â”œâ”€â”€ criterion.py           
â”‚   â”œâ”€â”€ custom_model.py           
â”‚   â”‚â”€â”€ dataloader.py         
â”‚   â”‚â”€â”€ feature.py       
â”‚   â”‚â”€â”€ model.py
â”‚   â”‚â”€â”€ optimizer.py         
â”‚   â”‚â”€â”€ scheduler.py       
â”‚   â”‚â”€â”€ trainer.py                  
|   â””â”€â”€ utils.py
|
â”œâ”€â”€ code/                     - DLíŒ€ ì½”ë“œ í´ë”
â”‚   â”œâ”€â”€ args.py           
â”‚   â”œâ”€â”€ inference.py           
â”‚   â”‚â”€â”€ inference_kfold.py         
â”‚   â”‚â”€â”€ train.py       
â”‚   â”‚â”€â”€ train_kfold.py                  
|   â””â”€â”€ train_stfkfold.py
â”‚
â”œâ”€â”€ notebook_pycaret          - MLíŒ€ ì½”ë“œ í´ë”
|   â”œâ”€â”€ Add_Feature_with_Groupby.ipynb
|   â”œâ”€â”€ get_logsì—°ìŠµí•´ë³´ê¸°.ipynb
|   â”œâ”€â”€ kaggle_riid_ì „ì²˜ë¦¬.ipynb
|   â”œâ”€â”€ LGBM_Validì›í•˜ëŠ”ëŒ€ë¡œêµ¬ì¶•ì„±ê³µ.ipynb
â”‚   â”œâ”€â”€ Optuna_LightGBM_ë¬¸ì œì‹œê°„ê°„ê²©í›„ì²˜ë¦¬X.ipynb
â”‚   â”œâ”€â”€ outputíŒŒì¼_bestë‘ë¹„êµí•´ë³´ê¸°.ipynb
|   â””â”€â”€ PermutationImportance.ipynb
|
â””â”€â”€ notebooks              
    â”œâ”€â”€ baseline.ipynb
    â”œâ”€â”€ EDA_Minyong.ipynb            
    â”œâ”€â”€ EDA-arabae.ipynb
    â”œâ”€â”€ hard_and_soft_ensemble.ipynb
    â”œâ”€â”€ output_confidence.ipynb
    â””â”€â”€ Riiid_pretrain.ipynb

```


# ğŸ… _Members_

**ê°•ë¯¼ìš© T1001**
**[[Github](https://github.com/MignonDeveloper)]  [[Blog](https://mignontraveler.tistory.com/)]**

- EDA
- GRU + Attention & SAINT Modeling
- User Data Augmentation, Pseudo Labeling
- Deep Learning Code ê°œì„ 
- DKT, DKT+, DKVMN ë…¼ë¬¸ ì •ë¦¬ ë° ê³µìœ 

> #ï¸âƒ£**463ë²ˆ ì‹¤í—˜**  #ï¸âƒ£**ì¼ë‹¨ ê³µìœ í•´** #ï¸âƒ£**ì–´í”¼ì¹˜**

---

**ê¹€ì§„í˜„ T1248**
**[[Github](https://github.com/KimJinHye0n)]  [Blog]**

- EDA
- Saint, Saint+ Modeling
- Feature Searching (ë¬¸í•­ë³„ ë‚œì´ë„ / KnowledgeTag)
- Ensemble (Hard + Soft voting)

---
**ë¬¸ì¬í›ˆ T1058**

**[[Github](https://github.com/MoonJaeHoon)]  [[Blog](https://moonjaehoon.github.io/)]**

- ML (with Customized Optuna & Pycaret)
- ê²€ì¦ì „ëµ (HoldOut Set, Customized CV)
- Efficient Feature Engineering (with Pandas method)
- Feature Selection (with Permutation Importance)
- Riiid Dataset Processing for Pre-training

---

**ë°°ì•„ë¼ T1084**

**[[Github](https://github.com/arabae)]  [[Blog](https://arabae.github.io/)]**

- LSTM, LSTM+Attention, BERT, CNN, Last Query, SAINT ë“±
ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬í˜„ ë° ì‹¤í—˜
- Userë³„ Feature Engineering
- Deep Learning Code ê°œì„ 
- Riiid ë°ì´í„°ë¥¼ í™œìš©í•œ pre-train ì‹œë„
- Ensemble (soft-voting, weighted soft-voting)

---


**ì´ì •í˜„ T1160**

**[[Github](https://github.com/gvsteve24)]  [[Blog](https://dipndeep.tistory.com/)]**

- EDA
- RNNê³„ì—´(LSTM, LSTM+Attention) ëª¨ë¸ ì‹¤í—˜
- DKT, DKVMN ë…¼ë¬¸ì •ë¦¬
- Riiid Competition Data Analysis for Transfer Learning
- íšŒì˜ ë‚´ìš© ì •ë¦¬

---

**ìµœìœ ë¼ T1212**    

**[[Github](https://github.com/Yuuraa)]  [[Blog](https://velog.io/@yoorachoi)]**

- EDA - í•™ìŠµ ë°ì´í„°, í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í¬ íŒŒì•…
- Feature engineering - í’€ì´ ì‹œê°„, ì •í™•ë„ í‰ê·  feature ì¶”ê°€
- ML ëª¨ë¸ í•™ìŠµ - LightGBM, XGBoost, CatBoost
- Validation set ì°¾ê¸°
